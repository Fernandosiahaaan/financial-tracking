version: '3'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data  # Menyimpan data di volume Elasticsearch
    networks:
      - defaults

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    environment:
      - LOGSTASH_HOST=logstash
    volumes:
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
    networks:
      - defaults

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - defaults
  
  postgres:
    image: postgres
    container_name: postgres
    platform: linux/amd64
    ports:
      - "5433:5432"
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin123
      POSTGRES_DB: financial-tracking
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - defaults

  redis:
    image: redis
    container_name: redis
    platform: linux/amd64
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - defaults

  mysql:
    image: mysql:5.7
    container_name: mysql
    platform: linux/amd64
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: mydatabase
      MYSQL_USER: user
      MYSQL_PASSWORD: password
    networks:
      - defaults

  mongodb:
    image: mongo:4.4
    container_name: mongodb
    platform: linux/amd64
    ports:
      - "27017:27017"   
    volumes:
      - mongo_data:/data/db  # Volume for persistent data
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin    
      MONGO_INITDB_ROOT_PASSWORD: password 
      MONGO_INITDB_DATABASE: task_management_logs
    # healthcheck:
    #   test: ["CMD", "mongo", "--eval", "db.runCommand({ ping: 1 })"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 5
    networks:
      - defaults
  
  # Prometheus
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - defaults

  # Grafana
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
    networks:
      - defaults

  # Kafka & Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"
    networks:
      - defaults

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper
    networks:
      - defaults

networks:
  defaults:
    driver: bridge

volumes:
  esdata:
    # driver: local  # Gunakan driver volume lokal untuk data Elasticsearch
  postgres_data:
  mongo_data:
    # driver: local
